# -*- coding: utf-8 -*-
"""CIS_9660_Exploratory_Data_Analysis_Class_practice.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-ZA7uNkzFp_lTcyHIFLmAwP9C6qMDWzv

# ğŸ” Exploratory Data Analysis: Online Retail Dataset

**CIS 9660 - Data Mining for Business Analytics**  
**Class #2: Data Reporting & Visualization Agents**

---

## ğŸ“‹ Learning Objectives
By the end of this tutorial, you will be able to:
- Load and inspect a real business dataset
- Identify and handle data quality issues
- Create meaningful visualizations for business insights
- Ask and answer data-driven business questions
- Prepare data for further analysis

---

## ğŸ“¦ Dataset Overview
**Source:** UCI Machine Learning Repository  
**Business:** UK-based online retail company specializing in unique all-occasion gifts  
**Time Period:** December 2010 - December 2011  
**Size:** 541,909 transactions  
**Customers:** Mix of wholesalers and individual buyers from 37 countries

## 1ï¸âƒ£ Setup and Data Loading
"""

# Import essential libraries
import pandas as pd # Lets you work with tables and spreadsheets (great for data).
import numpy as np # Helps with math and big lists of numbers (arrays).
import matplotlib.pyplot as plt # Used to draw graphs and charts for visualization.
import seaborn as sns # create statistical data visualizations like Histogram, Bar Plot, Scatter Plot
from datetime import datetime # is used to work with dates and times in Python
import warnings # Lets you show or hide warning messages.

# Configure visualization settings
plt.style.use('seaborn-v0_8') # Makes plots look like Seaborn style (older version)
sns.set_palette("husl") # Sets the color style for plots (HUSL = colorful and clear).
plt.rcParams['figure.figsize'] = (12, 8) # Sets default plot size to 12x8 inches
warnings.filterwarnings('ignore') # Hides warning messages to keep output clean

# Prints a success message
print("âœ… Libraries imported successfully!")

# Load the dataset from UCI Repository
# Method 1: Direct URL (recommended for class)
url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00352/Online%20Retail.xlsx'

print("ğŸ“¥ Loading dataset from UCI Repository...")
df = pd.read_excel(url)
print(f"âœ… Dataset loaded successfully! Shape: {df.shape}")

# Alternative methods if URL doesn't work:
# Method 2: Upload file to Colab
# from google.colab import files
# uploaded = files.upload()
# df = pd.read_excel('Online Retail.xlsx')

# Method 3: From Google Drive
# from google.colab import drive
# drive.mount('/content/drive')
# df = pd.read_excel('/content/drive/MyDrive/Online_Retail.xlsx')

"""## 2ï¸âƒ£ First Look at the Data"""

# Basic dataset information
print("ğŸ“Š DATASET OVERVIEW")
print("=" * 50)
print(f"Dataset shape: {df.shape}")
print(f"Rows: {df.shape[0]:,}")
print(f"Columns: {df.shape[1]}")
print(f"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB")

# Display first few rows
print("ğŸ” FIRST 5 ROWS")
print("=" * 50)
df.head()

# Column information
print("ğŸ“‹ COLUMN INFORMATION")
print("=" * 50)
df.info()

# Statistical summary
print("ğŸ“ˆ STATISTICAL SUMMARY")
print("=" * 50)
df.describe()

"""## 3ï¸âƒ£ Data Quality Assessment"""

# Check for missing values
print("ğŸ•³ï¸ MISSING VALUES ANALYSIS")
print("=" * 50)
missing_data = df.isnull().sum()
missing_percent = (missing_data / len(df)) * 100

missing_df = pd.DataFrame({
    'Missing Count': missing_data,
    'Percentage': missing_percent
})

print(missing_df[missing_df['Missing Count'] > 0])

# Visualize missing data
plt.figure(figsize=(10, 6))
missing_df[missing_df['Missing Count'] > 0]['Percentage'].plot(kind='bar', color='coral')
plt.title('Missing Data by Column', fontsize=16, fontweight='bold')
plt.ylabel('Percentage Missing (%)')
plt.xlabel('Columns')
plt.xticks(rotation=45)
plt.grid(axis='y', alpha=0.3)
plt.show()

# Check for duplicates
print("ğŸ”„ DUPLICATE ANALYSIS")
print("=" * 50)
duplicates = df.duplicated().sum()
print(f"Total duplicate rows: {duplicates:,}")
print(f"Percentage of duplicates: {(duplicates/len(df)*100):.2f}%")

if duplicates > 0:
    print("\nğŸ“‹ Sample duplicate rows:")
    print(df[df.duplicated()].head())

# Examine unique values in key columns
print("ğŸ”¢ UNIQUE VALUES ANALYSIS")
print("=" * 50)
for col in df.columns:
    unique_count = df[col].nunique()
    print(f"{col}: {unique_count:,} unique values")

print(f"\nğŸŒ Countries represented:")
print(df['Country'].value_counts().head(10))

"""## 4ï¸âƒ£ Business Questions & Analysis

### ğŸ¤” Business Question 1: What are the data quality issues we need to address?
"""

# Examine negative quantities (returns/cancellations)
print("âŒ NEGATIVE QUANTITIES ANALYSIS")
print("=" * 50)
negative_qty = df[df['Quantity'] < 0]
print(f"Transactions with negative quantities: {len(negative_qty):,}")
print(f"Percentage: {(len(negative_qty)/len(df)*100):.2f}%")

print("\nğŸ“‹ Sample negative quantity transactions:")
print(negative_qty[['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'UnitPrice']].head())

# Examine zero/negative unit prices
print("ğŸ’° UNIT PRICE ANALYSIS")
print("=" * 50)
zero_price = df[df['UnitPrice'] <= 0]
print(f"Transactions with zero/negative unit price: {len(zero_price):,}")
print(f"Percentage: {(len(zero_price)/len(df)*100):.2f}%")

if len(zero_price) > 0:
    print("\nğŸ“‹ Sample zero price transactions:")
    print(zero_price[['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'UnitPrice']].head())

# Create a clean dataset for analysis
print("ğŸ§¹ DATA CLEANING")
print("=" * 50)
print(f"Original dataset size: {len(df):,} rows")

# Remove rows with missing CustomerID (can't do customer analysis without it)
df_clean = df.dropna(subset=['CustomerID']).copy()
print(f"After removing missing CustomerID: {len(df_clean):,} rows")

# Remove transactions with negative quantities (returns/cancellations)
df_clean = df_clean[df_clean['Quantity'] > 0]
print(f"After removing negative quantities: {len(df_clean):,} rows")

# Remove transactions with zero/negative unit prices
df_clean = df_clean[df_clean['UnitPrice'] > 0]
print(f"After removing zero/negative prices: {len(df_clean):,} rows")

# Calculate total amount for each transaction
df_clean['TotalAmount'] = df_clean['Quantity'] * df_clean['UnitPrice']

print(f"\nâœ… Clean dataset ready: {len(df_clean):,} rows")
print(f"Data retention: {(len(df_clean)/len(df)*100):.1f}%")

"""### ğŸ¤” Business Question 2: When do customers shop most?"""

# Convert InvoiceDate to datetime and extract time components
df_clean['InvoiceDate'] = pd.to_datetime(df_clean['InvoiceDate'])
df_clean['Year'] = df_clean['InvoiceDate'].dt.year
df_clean['Month'] = df_clean['InvoiceDate'].dt.month
df_clean['DayOfWeek'] = df_clean['InvoiceDate'].dt.day_name()
df_clean['Hour'] = df_clean['InvoiceDate'].dt.hour

# Sales by month
monthly_sales = df_clean.groupby('Month').agg({
    'TotalAmount': 'sum',
    'InvoiceNo': 'nunique'
}).round(2)
monthly_sales.columns = ['Total_Revenue', 'Number_of_Orders']

# Create subplots for temporal analysis
fig, axes = plt.subplots(2, 2, figsize=(16, 12))
fig.suptitle('ğŸ“… Temporal Sales Analysis', fontsize=20, fontweight='bold')

# Monthly revenue
monthly_sales['Total_Revenue'].plot(kind='bar', ax=axes[0,0], color='skyblue')
axes[0,0].set_title('Monthly Revenue', fontweight='bold')
axes[0,0].set_xlabel('Month')
axes[0,0].set_ylabel('Revenue (Â£)')
axes[0,0].tick_params(axis='x', rotation=0)

# Monthly order count
monthly_sales['Number_of_Orders'].plot(kind='bar', ax=axes[0,1], color='lightcoral')
axes[0,1].set_title('Monthly Order Count', fontweight='bold')
axes[0,1].set_xlabel('Month')
axes[0,1].set_ylabel('Number of Orders')
axes[0,1].tick_params(axis='x', rotation=0)

# Day of week analysis
day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
day_sales = df_clean.groupby('DayOfWeek')['TotalAmount'].sum().reindex(day_order)
day_sales.plot(kind='bar', ax=axes[1,0], color='lightgreen')
axes[1,0].set_title('Sales by Day of Week', fontweight='bold')
axes[1,0].set_xlabel('Day of Week')
axes[1,0].set_ylabel('Revenue (Â£)')
axes[1,0].tick_params(axis='x', rotation=45)

# Hourly analysis
hourly_sales = df_clean.groupby('Hour')['TotalAmount'].sum()
hourly_sales.plot(kind='line', ax=axes[1,1], color='purple', marker='o')
axes[1,1].set_title('Sales by Hour of Day', fontweight='bold')
axes[1,1].set_xlabel('Hour')
axes[1,1].set_ylabel('Revenue (Â£)')
axes[1,1].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

print("ğŸ“Š KEY INSIGHTS:")
print(f"ğŸ”¥ Peak month: {monthly_sales['Total_Revenue'].idxmax()} (Â£{monthly_sales['Total_Revenue'].max():,.0f})")
print(f"ğŸ“… Best day: {day_sales.idxmax()} (Â£{day_sales.max():,.0f})")
print(f"â° Peak hour: {hourly_sales.idxmax()}:00 (Â£{hourly_sales.max():,.0f})")

"""### ğŸ¤” Business Question 3: What are our best-selling products?"""

# Product analysis
product_stats = df_clean.groupby(['StockCode', 'Description']).agg({
    'Quantity': 'sum',
    'TotalAmount': 'sum',
    'InvoiceNo': 'nunique'
}).round(2)
product_stats.columns = ['Total_Quantity', 'Total_Revenue', 'Number_of_Orders']
product_stats = product_stats.reset_index()

# Top products by different metrics
fig, axes = plt.subplots(1, 3, figsize=(20, 6))
fig.suptitle('ğŸ† Top Products Analysis', fontsize=20, fontweight='bold')

# Top by quantity
top_qty = product_stats.nlargest(10, 'Total_Quantity')
axes[0].barh(range(len(top_qty)), top_qty['Total_Quantity'], color='lightblue')
axes[0].set_yticks(range(len(top_qty)))
axes[0].set_yticklabels([desc[:30] + '...' if len(desc) > 30 else desc for desc in top_qty['Description']])
axes[0].set_title('Top 10 by Quantity Sold')
axes[0].set_xlabel('Total Quantity')

# Top by revenue
top_rev = product_stats.nlargest(10, 'Total_Revenue')
axes[1].barh(range(len(top_rev)), top_rev['Total_Revenue'], color='lightcoral')
axes[1].set_yticks(range(len(top_rev)))
axes[1].set_yticklabels([desc[:30] + '...' if len(desc) > 30 else desc for desc in top_rev['Description']])
axes[1].set_title('Top 10 by Revenue')
axes[1].set_xlabel('Total Revenue (Â£)')

# Top by order frequency
top_freq = product_stats.nlargest(10, 'Number_of_Orders')
axes[2].barh(range(len(top_freq)), top_freq['Number_of_Orders'], color='lightgreen')
axes[2].set_yticks(range(len(top_freq)))
axes[2].set_yticklabels([desc[:30] + '...' if len(desc) > 30 else desc for desc in top_freq['Description']])
axes[2].set_title('Top 10 by Order Frequency')
axes[2].set_xlabel('Number of Orders')

plt.tight_layout()
plt.show()

print("ğŸ† TOP PRODUCT INSIGHTS:")
print(f"ğŸ“¦ Most sold item: {top_qty.iloc[0]['Description']} ({top_qty.iloc[0]['Total_Quantity']:,.0f} units)")
print(f"ğŸ’° Highest revenue: {top_rev.iloc[0]['Description']} (Â£{top_rev.iloc[0]['Total_Revenue']:,.0f})")
print(f"ğŸ”„ Most frequent: {top_freq.iloc[0]['Description']} ({top_freq.iloc[0]['Number_of_Orders']:,.0f} orders)")

"""### ğŸ¤” Business Question 4: Who are our most valuable customers?"""

# Customer analysis
customer_stats = df_clean.groupby('CustomerID').agg({
    'TotalAmount': ['sum', 'mean', 'count'],
    'Quantity': 'sum',
    'InvoiceDate': ['min', 'max']
}).round(2)

# Flatten column names
customer_stats.columns = ['Total_Spent', 'Avg_Order_Value', 'Number_of_Orders', 'Total_Items', 'First_Purchase', 'Last_Purchase']
customer_stats = customer_stats.reset_index()

# Calculate customer lifetime (days)
customer_stats['Customer_Lifetime_Days'] = (customer_stats['Last_Purchase'] - customer_stats['First_Purchase']).dt.days

# Customer segmentation visualization
fig, axes = plt.subplots(2, 2, figsize=(16, 12))
fig.suptitle('ğŸ‘¥ Customer Analysis', fontsize=20, fontweight='bold')

# Distribution of total spent
axes[0,0].hist(customer_stats['Total_Spent'], bins=50, color='skyblue', alpha=0.7)
axes[0,0].set_title('Distribution of Total Customer Spending')
axes[0,0].set_xlabel('Total Spent (Â£)')
axes[0,0].set_ylabel('Number of Customers')
axes[0,0].axvline(customer_stats['Total_Spent'].mean(), color='red', linestyle='--', label=f'Mean: Â£{customer_stats["Total_Spent"].mean():.0f}')
axes[0,0].legend()

# Distribution of order frequency
axes[0,1].hist(customer_stats['Number_of_Orders'], bins=50, color='lightcoral', alpha=0.7)
axes[0,1].set_title('Distribution of Order Frequency')
axes[0,1].set_xlabel('Number of Orders')
axes[0,1].set_ylabel('Number of Customers')
axes[0,1].axvline(customer_stats['Number_of_Orders'].mean(), color='red', linestyle='--', label=f'Mean: {customer_stats["Number_of_Orders"].mean():.1f}')
axes[0,1].legend()

# Scatter plot: Orders vs Spending
axes[1,0].scatter(customer_stats['Number_of_Orders'], customer_stats['Total_Spent'], alpha=0.6, color='green')
axes[1,0].set_title('Orders vs Total Spending')
axes[1,0].set_xlabel('Number of Orders')
axes[1,0].set_ylabel('Total Spent (Â£)')

# Average order value distribution
axes[1,1].hist(customer_stats['Avg_Order_Value'], bins=50, color='purple', alpha=0.7)
axes[1,1].set_title('Distribution of Average Order Value')
axes[1,1].set_xlabel('Average Order Value (Â£)')
axes[1,1].set_ylabel('Number of Customers')
axes[1,1].axvline(customer_stats['Avg_Order_Value'].mean(), color='red', linestyle='--', label=f'Mean: Â£{customer_stats["Avg_Order_Value"].mean():.0f}')
axes[1,1].legend()

plt.tight_layout()
plt.show()

# Top customers
print("ğŸ‘‘ TOP 10 CUSTOMERS BY TOTAL SPENDING:")
top_customers = customer_stats.nlargest(10, 'Total_Spent')[['CustomerID', 'Total_Spent', 'Number_of_Orders', 'Avg_Order_Value']]
print(top_customers.to_string(index=False))

print(f"\nğŸ“Š CUSTOMER INSIGHTS:")
print(f"ğŸ’° Average customer value: Â£{customer_stats['Total_Spent'].mean():.2f}")
print(f"ğŸ›’ Average orders per customer: {customer_stats['Number_of_Orders'].mean():.1f}")
print(f"ğŸ’³ Average order value: Â£{customer_stats['Avg_Order_Value'].mean():.2f}")
print(f"ğŸ” Top 10% customers contribute: {(customer_stats.nlargest(int(len(customer_stats)*0.1), 'Total_Spent')['Total_Spent'].sum() / customer_stats['Total_Spent'].sum() * 100):.1f}% of revenue")

"""### ğŸ¤” Business Question 5: Which countries generate the most revenue?"""

# Country analysis
country_stats = df_clean.groupby('Country').agg({
    'TotalAmount': 'sum',
    'CustomerID': 'nunique',
    'InvoiceNo': 'nunique',
    'Quantity': 'sum'
}).round(2)
country_stats.columns = ['Total_Revenue', 'Unique_Customers', 'Number_of_Orders', 'Total_Quantity']
country_stats = country_stats.sort_values('Total_Revenue', ascending=False).reset_index()

# Create visualization
fig, axes = plt.subplots(2, 2, figsize=(16, 12))
fig.suptitle('ğŸŒ Geographic Analysis', fontsize=20, fontweight='bold')

# Top countries by revenue
top_countries = country_stats.head(15)
axes[0,0].barh(range(len(top_countries)), top_countries['Total_Revenue'], color='gold')
axes[0,0].set_yticks(range(len(top_countries)))
axes[0,0].set_yticklabels(top_countries['Country'])
axes[0,0].set_title('Top 15 Countries by Revenue')
axes[0,0].set_xlabel('Total Revenue (Â£)')

# Countries by customer count
top_customers_country = country_stats.head(10)
axes[0,1].bar(range(len(top_customers_country)), top_customers_country['Unique_Customers'], color='lightblue')
axes[0,1].set_xticks(range(len(top_customers_country)))
axes[0,1].set_xticklabels(top_customers_country['Country'], rotation=45)
axes[0,1].set_title('Top 10 Countries by Customer Count')
axes[0,1].set_ylabel('Number of Customers')

# Revenue distribution (pie chart for top 10)
top_10_countries = country_stats.head(10)
others_revenue = country_stats.iloc[10:]['Total_Revenue'].sum()
pie_data = list(top_10_countries['Total_Revenue']) + [others_revenue]
pie_labels = list(top_10_countries['Country']) + ['Others']

axes[1,0].pie(pie_data, labels=pie_labels, autopct='%1.1f%%', startangle=90)
axes[1,0].set_title('Revenue Distribution by Country')

# Average order value by country (top 10)
country_stats['Avg_Order_Value'] = country_stats['Total_Revenue'] / country_stats['Number_of_Orders']
top_aov = country_stats.head(10)
axes[1,1].bar(range(len(top_aov)), top_aov['Avg_Order_Value'], color='lightgreen')
axes[1,1].set_xticks(range(len(top_aov)))
axes[1,1].set_xticklabels(top_aov['Country'], rotation=45)
axes[1,1].set_title('Average Order Value by Country (Top 10)')
axes[1,1].set_ylabel('Average Order Value (Â£)')

plt.tight_layout()
plt.show()

print("ğŸŒ GEOGRAPHIC INSIGHTS:")
print(f"ğŸ¥‡ Top revenue country: {country_stats.iloc[0]['Country']} (Â£{country_stats.iloc[0]['Total_Revenue']:,.0f})")
print(f"ğŸ‘¥ Most customers: {country_stats.loc[country_stats['Unique_Customers'].idxmax(), 'Country']} ({country_stats['Unique_Customers'].max():,} customers)")
print(f"ğŸ’³ Highest AOV: {country_stats.loc[country_stats['Avg_Order_Value'].idxmax(), 'Country']} (Â£{country_stats['Avg_Order_Value'].max():.2f})")
print(f"ğŸ´ó §ó ¢ó ¥ó ®ó §ó ¿ UK dominance: {(country_stats[country_stats['Country'] == 'United Kingdom']['Total_Revenue'].values[0] / country_stats['Total_Revenue'].sum() * 100):.1f}% of total revenue")

"""### ğŸ¤” Business Question 6: Are there seasonal patterns?"""

# Create date-based aggregations for time series analysis
df_clean['Date'] = df_clean['InvoiceDate'].dt.date
daily_sales = df_clean.groupby('Date').agg({
    'TotalAmount': 'sum',
    'InvoiceNo': 'nunique',
    'CustomerID': 'nunique'
}).reset_index()
daily_sales.columns = ['Date', 'Daily_Revenue', 'Daily_Orders', 'Daily_Customers']
daily_sales['Date'] = pd.to_datetime(daily_sales['Date'])

# Weekly aggregation
daily_sales['Week'] = daily_sales['Date'].dt.isocalendar().week
daily_sales['Month'] = daily_sales['Date'].dt.month
daily_sales['Year'] = daily_sales['Date'].dt.year

# Create seasonal analysis
fig, axes = plt.subplots(2, 2, figsize=(20, 12))
fig.suptitle('ğŸ“… Seasonal Patterns Analysis', fontsize=20, fontweight='bold')

# Daily revenue time series
axes[0,0].plot(daily_sales['Date'], daily_sales['Daily_Revenue'], color='blue', alpha=0.7)
axes[0,0].set_title('Daily Revenue Over Time')
axes[0,0].set_xlabel('Date')
axes[0,0].set_ylabel('Daily Revenue (Â£)')
axes[0,0].grid(True, alpha=0.3)

# Monthly revenue boxplot
monthly_data = df_clean.groupby([df_clean['InvoiceDate'].dt.to_period('M')])['TotalAmount'].sum().reset_index()
monthly_data['Month'] = monthly_data['InvoiceDate'].dt.month
month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']
sns.boxplot(data=df_clean, x='Month', y='TotalAmount', ax=axes[0,1])
axes[0,1].set_title('Revenue Distribution by Month')
axes[0,1].set_xlabel('Month')
axes[0,1].set_ylabel('Transaction Amount (Â£)')
axes[0,1].set_xticklabels(month_names)

# Weekly pattern
weekly_avg = daily_sales.groupby('Week')['Daily_Revenue'].mean()
axes[1,0].plot(weekly_avg.index, weekly_avg.values, marker='o', color='green')
axes[1,0].set_title('Average Weekly Revenue Pattern')
axes[1,0].set_xlabel('Week of Year')
axes[1,0].set_ylabel('Average Daily Revenue (Â£)')
axes[1,0].grid(True, alpha=0.3)

# Quarterly comparison
df_clean['Quarter'] = df_clean['InvoiceDate'].dt.quarter
quarterly_sales = df_clean.groupby('Quarter')['TotalAmount'].sum()
axes[1,1].bar(['Q1', 'Q2', 'Q3', 'Q4'], quarterly_sales.values, color=['lightblue', 'lightgreen', 'lightyellow', 'lightcoral'])
axes[1,1].set_title('Quarterly Revenue Comparison')
axes[1,1].set_xlabel('Quarter')
axes[1,1].set_ylabel('Total Revenue (Â£)')

# Add value labels on bars
for i, v in enumerate(quarterly_sales.values):
    axes[1,1].text(i, v + 50000, f'Â£{v:,.0f}', ha='center', va='bottom')

plt.tight_layout()
plt.show()

print("ğŸ“… SEASONAL INSIGHTS:")
peak_month = df_clean.groupby('Month')['TotalAmount'].sum().idxmax()
peak_quarter = quarterly_sales.idxmax()
print(f"ğŸ”¥ Peak month: {month_names[peak_month-1]} (Month {peak_month})")
print(f"ğŸ“ˆ Peak quarter: Q{peak_quarter} (Â£{quarterly_sales[peak_quarter]:,.0f})")
print(f"ğŸ“Š Q4 vs Q1 growth: {((quarterly_sales[4] / quarterly_sales[1] - 1) * 100):+.1f}%")
print(f"ğŸ„ Holiday shopping effect: Clear revenue spike in November-December")

"""## 5ï¸âƒ£ Summary Dashboard"""

# Create a comprehensive summary dashboard
fig = plt.figure(figsize=(20, 16))
fig.suptitle('ğŸ“Š Online Retail Business Dashboard', fontsize=24, fontweight='bold', y=0.98)

# Key metrics at the top
metrics_text = f"""
ğŸ¯ KEY BUSINESS METRICS (Dec 2010 - Dec 2011)
{'='*80}
ğŸ’° Total Revenue: Â£{df_clean['TotalAmount'].sum():,.0f}
ğŸ“¦ Total Transactions: {len(df_clean):,}
ğŸ‘¥ Unique Customers: {df_clean['CustomerID'].nunique():,}
ğŸŒ Countries Served: {df_clean['Country'].nunique()}
ğŸ›ï¸ Unique Products: {df_clean['StockCode'].nunique():,}
ğŸ’³ Average Order Value: Â£{df_clean['TotalAmount'].mean():.2f}
ğŸ“… Peak Month: {month_names[df_clean.groupby('Month')['TotalAmount'].sum().idxmax()-1]}
ğŸ† Top Country: {country_stats.iloc[0]['Country']} ({(country_stats.iloc[0]['Total_Revenue'] / country_stats['Total_Revenue'].sum() * 100):.1f}% of revenue)
"""

plt.figtext(0.05, 0.85, metrics_text, fontsize=14, fontfamily='monospace',
           bbox=dict(boxstyle="round,pad=1", facecolor="lightblue", alpha=0.8))

# Revenue trend
ax1 = plt.subplot(3, 3, (4, 6))
monthly_revenue = df_clean.groupby('Month')['TotalAmount'].sum()
ax1.plot(monthly_revenue.index, monthly_revenue.values, marker='o', linewidth=3, markersize=8, color='navy')
ax1.fill_between(monthly_revenue.index, monthly_revenue.values, alpha=0.3, color='skyblue')
ax1.set_title('Monthly Revenue Trend', fontsize=16, fontweight='bold')
ax1.set_xlabel('Month')
ax1.set_ylabel('Revenue (Â£)')
ax1.grid(True, alpha=0.3)

# Top countries pie chart
ax2 = plt.subplot(3, 3, 7)
top_5_countries = country_stats.head(5)
others_rev = country_stats.iloc[5:]['Total_Revenue'].sum()
pie_data = list(top_5_countries['Total_Revenue']) + [others_rev]
pie_labels = list(top_5_countries['Country']) + ['Others']
ax2.pie(pie_data, labels=pie_labels, autopct='%1.1f%%', startangle=90)
ax2.set_title('Revenue by Country', fontsize=14, fontweight='bold')

# Customer distribution
ax3 = plt.subplot(3, 3, 8)
customer_bins = [0, 100, 500, 1000, 5000, float('inf')]
customer_labels = ['Â£0-99', 'Â£100-499', 'Â£500-999', 'Â£1000-4999', 'Â£5000+']
customer_stats['Spending_Segment'] = pd.cut(customer_stats['Total_Spent'], bins=customer_bins, labels=customer_labels, right=False)
segment_counts = customer_stats['Spending_Segment'].value_counts()
ax3.bar(segment_counts.index, segment_counts.values, color='lightgreen')
ax3.set_title('Customer Segments', fontsize=14, fontweight='bold')
ax3.set_xlabel('Spending Range')
ax3.set_ylabel('Number of Customers')
ax3.tick_params(axis='x', rotation=45)

# Top products
ax4 = plt.subplot(3, 3, 9)
top_5_products = product_stats.nlargest(5, 'Total_Revenue')
product_names = [name[:20] + '...' if len(name) > 20 else name for name in top_5_products['Description']]
ax4.barh(range(len(top_5_products)), top_5_products['Total_Revenue'], color='orange')
ax4.set_yticks(range(len(top_5_products)))
ax4.set_yticklabels(product_names)
ax4.set_title('Top Products by Revenue', fontsize=14, fontweight='bold')
ax4.set_xlabel('Revenue (Â£)')

plt.tight_layout()
plt.subplots_adjust(top=0.85, bottom=0.1)
plt.show()

"""## 6ï¸âƒ£ Key Findings & Business Recommendations"""

print("ğŸ¯ KEY FINDINGS & BUSINESS RECOMMENDATIONS")
print("=" * 60)

print("\nğŸ“Š DATA QUALITY INSIGHTS:")
print(f"â€¢ {(len(df) - len(df_clean))/len(df)*100:.1f}% of data required cleaning")
print(f"â€¢ {df['CustomerID'].isnull().sum():,} transactions missing customer info")
print(f"â€¢ {len(df[df['Quantity'] < 0]):,} return/cancellation transactions")

print("\nğŸ¯ BUSINESS OPPORTUNITIES:")
uk_revenue_pct = country_stats[country_stats['Country'] == 'United Kingdom']['Total_Revenue'].values[0] / country_stats['Total_Revenue'].sum() * 100
print(f"â€¢ UK dominates with {uk_revenue_pct:.1f}% of revenue - explore international expansion")
print(f"â€¢ Clear seasonality - {month_names[df_clean.groupby('Month')['TotalAmount'].sum().idxmax()-1]} peak suggests holiday shopping")
print(f"â€¢ Customer concentration - top 10% generate {(customer_stats.nlargest(int(len(customer_stats)*0.1), 'Total_Spent')['Total_Spent'].sum() / customer_stats['Total_Spent'].sum() * 100):.1f}% of revenue")

print("\nğŸš€ RECOMMENDED ACTIONS:")
print("â€¢ Implement customer retention programs for high-value segments")
print("â€¢ Expand marketing in international markets (especially Europe)")
print("â€¢ Optimize inventory for seasonal demand patterns")
print("â€¢ Focus on wholesale customer acquisition (high AOV)")
print("â€¢ Improve data collection to reduce missing customer information")

print("\nğŸ“ WHAT WE LEARNED:")
print("â€¢ EDA reveals both opportunities and data quality issues")
print("â€¢ Visualizations make patterns immediately apparent")
print("â€¢ Business questions guide the analysis direction")
print("â€¢ Real data is messy - cleaning is essential")
print("â€¢ Multiple perspectives reveal different insights")

"""## 7ï¸âƒ£ Next Steps: Preparing for AI Agents"""

# Save the cleaned dataset for future use
print("ğŸ’¾ SAVING CLEANED DATASET FOR FUTURE ANALYSIS")
print("=" * 50)

# Add some derived features that could be useful for modeling
df_clean['Revenue_Per_Item'] = df_clean['TotalAmount'] / df_clean['Quantity']
df_clean['Is_Weekend'] = df_clean['DayOfWeek'].isin(['Saturday', 'Sunday'])
df_clean['Is_Holiday_Season'] = df_clean['Month'].isin([11, 12])  # Nov-Dec

# Create customer-level features for future modeling
customer_features = df_clean.groupby('CustomerID').agg({
    'TotalAmount': ['sum', 'mean', 'std', 'count'],
    'Quantity': ['sum', 'mean'],
    'InvoiceDate': ['min', 'max'],
    'Country': 'first',
    'StockCode': 'nunique'
}).round(2)

# Flatten column names
customer_features.columns = ['Total_Spent', 'Avg_Order_Value', 'Std_Order_Value', 'Order_Count',
                           'Total_Items', 'Avg_Items_Per_Order', 'First_Purchase', 'Last_Purchase',
                           'Country', 'Unique_Products']

customer_features['Days_Active'] = (customer_features['Last_Purchase'] - customer_features['First_Purchase']).dt.days + 1
customer_features['Avg_Days_Between_Orders'] = customer_features['Days_Active'] / customer_features['Order_Count']

print(f"âœ… Cleaned transaction data: {len(df_clean):,} rows, {len(df_clean.columns)} columns")
print(f"âœ… Customer features: {len(customer_features):,} customers, {len(customer_features.columns)} features")

print("\nğŸ¤– POTENTIAL AI AGENT APPLICATIONS:")
print("â€¢ Customer Churn Prediction Agent")
print("â€¢ Product Recommendation Agent")
print("â€¢ Inventory Forecasting Agent")
print("â€¢ Fraud Detection Agent")
print("â€¢ Price Optimization Agent")
print("â€¢ Customer Segmentation Agent")

print("\nğŸ“ˆ NEXT CLASS PREVIEW:")
print("â€¢ Building interactive dashboards with Streamlit")
print("â€¢ Creating visualization agents")
print("â€¢ Deploying your first data agent")

# Save datasets (in a real environment)
# df_clean.to_csv('online_retail_cleaned.csv', index=False)
# customer_features.to_csv('customer_features.csv', index=True)
print("\nğŸ’¡ TIP: In your projects, always save cleaned data for reuse!")

"""---


## ğŸš€ Ready for the Next Challenge?
Now that you understand your data, you're ready to build AI agents that can:
- Automatically generate these insights
- Create interactive dashboards
- Make predictions and recommendations
- Monitor business performance in real-time

**Next Class:** We'll build our first data visualization agent using Streamlit!

---
*"Data is the new oil, but insights are the new gold!"* ğŸ’°
"""